- [优化指标](#优化指标)
- [测量工具](#测量工具)
- [网络优化](#网络优化)
- [浏览器](#浏览器)
- [重绘 (Repaint) 回流 (Reflow)](#重绘-repaint-回流-reflow)
- [babel](#babel)
- [webpack](#webpack)
- [javascript](#javascript)
- [容器](#容器)
- [react](#react)
- [vue](#vue)
- [css](#css)
- [管理](#管理)

# 优化指标

web-vitals 是 Google 提出的一套网站用户体验的指标，

一般的优化指标可以通过 lighthouse 来测量，FP/FCP/LCP/FID/TTI/TBT。
Google 在 20 年五月提出了网站用户体验的三大核心指标 LCP/FID/CLS

First Paint 首次绘制（FP）这个指标用于记录页面第一次绘制像素的时间，如显示页面背景色。performance.timing.navigationStart、performance.getEntries()

First contentful paint 首次内容绘制 (FCP).是指页面开始加载到最大文本块内容或图片显示在页面中的时间。如果 FP 及 FCP 两指标在 2 秒内完成的话我们的页面就算体验优秀。

Largest contentful paint 最大内容绘制 (LCP). 用于记录视窗内最大的元素绘制的时间，该时间会随着页面渲染变化而变化，因为页面中的最大元素在渲染过程中可能会发生改变，另外该指标会在用户第一次交互后停止记录。PerformanceObserver

Time to Interactive 可交互时间 (TTI).首次可交互时间，TTI（Time to Interactive）。这个指标计算过程略微复杂，它需要满足以下几个条件：

First input delay 首次输入延迟 (FID).首次输入延迟，FID（First Input Delay），记录在 FCP 和 TTI 之间用户首次与页面交互时响应的延迟。

从 FCP 指标后开始计算。持续 5 秒内无长任务（执行时间超过 50 ms）且无两个以上正在进行中的 GET 请求。往前回溯至 5 秒前的最后一个长任务结束的时间。对于用户交互（比如点击事件），推荐的响应时间是 100ms 以内。那么为了达成这个目标，推荐在空闲时间里执行任务不超过 50ms（ W3C 也有这样的标准规定），这样能在用户无感知的情况下响应用户的交互，否则就会造成延迟感。

Total blocking time 总阻塞时间 (TBT)，阻塞总时间，TBT（Total Blocking Time），记录在 FCP 到 TTI 之间所有长任务的阻塞时间总和。

Cumulative layout shift 累积布局偏移 (CLS)。累计位移偏移，CLS（Cumulative Layout Shift），记录了页面上非预期的位移波动。页面渲染过程中突然插入一张巨大的图片或者说点击了某个按钮突然动态插入了一块内容等等相当影响用户体验的网站。这个指标就是为这种情况而生的，计算方式为：位移影响的面积 \* 位移距离。

# 测量工具

Lighthouse、在线 PageSpeed Insights、DevTools 的 Performance 面板、JS PerformanceObserver API。
一般我们的精力都放在优化 LCP 的时间：服务端响应时间、Javascript 和 CSS 引起的渲染卡顿、资源加载时间、客户端渲染
React 还可以启用 Profiler 面板看火焰图或者是使用 Profiler 组件进行性能分析

# 网络优化

尽量用 http2，http2 有多路复用，二进制分帧，头部压缩等特性，可以减少请求次数，减少请求头的大小，减少请求的延迟。
http1 的话就是尽可能减少请求数，细分域名、内联资源、合并文件。但其实这些优化对于 http2 来说是起到相反作用的。就比如细分域名这点，每个额外的域名都会带来额外的 DNS 查询、TCP 连接和 TLS 握手；因为 http/2 是基于流的，HTTP/2 的流优先级，浏览器不能跨域比较流的优先级，当然我的这个观点可能不那么准确，您不要见笑。

静态资源使用 CDN、合理利用缓存、使用 gzip 压缩、选择合适的图片来加载、减少请求头的大小(谨慎的使用 json web token，避免塞特别多的内容)。

另外业务开发上尽量少使用重定向，因为重定向会导致浏览器重新发起请求，这样就会增加请求的延迟。301/302

```shell
content-encoding: gzip

gzip  on;
gzip_min_length 1k;
gzip_buffers 4 16k;
gzip_comp_level 6;
gzip_types text/plain text/css text/xml application/javascript application/x-javascript application/xml application/json;
gzip_vary on;
gzip_disable "MSIE [1-6]\.";
```

# 浏览器

处理 HTML 并构建 DOM 树、处理 CSS 构建 CSS 规则树(CSSOM)、接着 JS 会通过 DOM Api 和 CSSOM Api 来操作 DOM Tree 和 CSS Rule Tree 合成一颗渲染树 Render Tree。
根据渲染树来布局，计算每个节点的位置，调用 GPU 绘制，合成图层，显示在屏幕上。

css 阻塞：浏览器在构建 CSSOM 的过程中，不会渲染任何已处理的内容，即便 DOM 已经解析完毕了。只有当我们开始解析 HTML 后、解析到 link 标签或者 style 标签时，CSS 才登场，CSSOM 的构建才开始。 很多时候，DOM 不得不等待 CSSOM。尽早（将 CSS 放在 head 标签里）和尽快（启用 CDN 实现静态资源加载速度的优化）

JS 阻塞。当 HTML 解析器遇到一个 script 标签时，它会暂停渲染过程，将控制权交给 JS 引擎。JS 引擎对内联的 JS 代码会直接执行，对外部 JS 文件还要先获取到脚本、再进行执行。等 JS 引擎运行完毕，浏览器又会把控制权还给渲染引擎，继续 CSSOM 和 DOM 的构建。之所以会阻塞对标签的解析是因为加载的 JS 中可能会创建，删除节点等，这些操作会对 DOM 树产生影响，如果不阻塞，等浏览器解析完标签生成 DOM 树后，JS 修改了某些节点，那么浏览器又得重新解析，然后生成 DOM 树，性能比较差。
defer 方式加载 script, 不会阻塞 HTML 解析，等到 DOM 生成完毕且 script 加载完毕再执行 JS。async 属性表示异步执行引入的 JS，加载时不会阻塞 HTML 解析，但是加载完成后立马执行，此时仍然会阻塞 load 事件。一般当我们的脚本与 DOM 元素和其它脚本之间的依赖关系不强时，我们会选用 async；当脚本依赖于 DOM 元素和其它脚本的执行结果时，我们会选用 defer。

css 还有一个特别的点，就是降低选择器的复杂度，但现在浏览器都很强了，我觉得这一点不用过于担心。

还可以利用 service worker 缓存请求，google 提供的 workbox 功能已经比较齐全了，可以拿来就用。

# 重绘 (Repaint) 回流 (Reflow)

回流：当 Render Tree 中部分或全部元素的尺寸、结构、或某些属性发生改变时，浏览器重新渲染部分或全部文档的过程称为回流。
重绘：当页面中元素样式的改变并不影响它在文档流中的位置时（例如：color、background-color、visibility 等），浏览器会将新样式赋予给元素并重新绘制它，这个过程称为重绘

回流必将引起重绘，重绘不一定会引起回流，回流比重绘的代价要更高。

浏览器窗口大小发生改变、元素尺寸或位置发生改变、元素内容变化（文字数量或图片大小等等）、元素字体大小变化、添加或者删除可见的 DOM 元素、激活 CSS 伪类（例如：:hover）

避免频繁操作样式，最好一次性重写 style 属性，或者将样式列表定义为 class 并一次性更改 class 属性。
避免频繁操作 DOM，创建一个 documentFragment，在它上面应用所有 DOM 操作，最后再把它添加到文档中。
离屏渲染，也可以先为元素设置 display: none，操作结束后再把它显示出来。因为在 display 属性为 none 的元素上进行的 DOM 操作不会引发回流和重绘。
避免频繁读取会引发回流/重绘的属性，client/offset/scroll/getComputedStyle/getBoundingClientRect/scrollTo/scrollIntoView 等
对具有复杂动画的元素使用绝对定位，使它脱离文档流，否则会引起父元素及后续元素频繁回流。

将频繁重绘或者回流的节点设置为图层，图层能够阻止该节点的渲染行为影响别的节点，例如 will-change、video、iframe 等标签，浏览器会自动将该节点变为图层。
CSS3 硬件加速（GPU 加速），使用 css3 硬件加速，可以让 transform、opacity、filters 这些动画不会引起回流重绘 。但是对于动画的其它属性，比如 background-color 这些，还是会引起回流重绘的，不过它还是可以提升这些动画的性能。

浏览器会维护一个队列，把所有引起回流和重绘的操作放入队列中，如果队列中的任务数量或者时间间隔达到一个阈值的，浏览器就会将队列清空，进行一次批处理，这样可以把多次回流和重绘变成一次。

# babel

对于工具库来说，babel 打包时要配置 transform-runtime，可以提取公共的 helper 函数，减少打包后的代码体积。理想是美好的，但实际上因为 babel/core 版本不一致可能会安装多个版本的 babel/core。

也可以设置兼容的浏览器版本，设置的越低打包出来的代码体积越大

# webpack

提取 externals，一些 lib 库通过 cdn 引入。这种方式对于单个项目来说总的需要加载的体积并没有减少，但是从长期来看，如果这些 lib 包在整个体系中被使用的话，那么这些 lib 包就会被浏览器缓存，从长远来看意义也是很大的。类似 externals，systemjs 也可以实现类似的功能。

写第三方库的时候也可以通过注释来标记纯函数 pure，或者是利用 sideEffect，这样可以让 tree shaking 掉一些不必要的代码。

hash：跟整个项目的构建相关，构建生成的文件 hash 值都是一样的，只要项目里有文件更改，整个项目构建的 hash 值都会更改。
chunkhash：根据不同的入口文件(Entry)进行依赖文件解析、构建对应的 chunk，生成对应的 hash 值。
contenthash：由文件内容产生的 hash 值，内容不同产生的 contenthash 值也不一样。
显然，我们是不会使用第一种的。改了一个文件，打包之后，其他文件的 hash 都变了，缓存自然都失效了。这不是我们想要的。

# javascript

常见的图片懒加载。react/vue 的路由懒加载。替换一些不能 treeShaking 的库，比如 lodash-es，monment dayjs，金额计算方面 mathjs 换 currency，按实际情况来选择。特殊情况下可以单独设计开发首页，比如首页用 svelte 开发，对后面的资源进行预加载。

js 里面的事件委托，因为现在都用 react/vue 了，所以这个问题不大，但是如果是原生的话，可以用事件委托来减少事件绑定的数量。

有一个特别的优化点是 fetch 请求可以 getReader 然后通过 ReadableStream 来实现流式读取，这样数据是一点点加到内存中，对于加载大量数据的情况下优势还是挺明显的，不过这个东西要做很多处理才敢用。

上传图片的预览方面，antd 和 elementui 用的是 base64(FileReader.readAsDataURL)，base64 格式的相比于原始文件来说体积会更大，这个时候可以用 URL.createObjectURL 来生成一个 blob url 来代替，只是需要自己去主动释放内存 revokeObjectURL。

同构渲染 SSR or 预渲染， 我这边做的大都是 B 端产品，平时对 srr 的了解不是很深，只知道 浏览器 api 不能随便用，renderToString，还有做些 lru 缓存优化这种。如果只是要支持 SEO 的话我建议直接花钱买流量或者是专门针对爬虫开发一个页面，这样的话也不需要做同构渲染了。劣势在于程序需要具有通用性。结合 Vue 的钩子来说，能在 SSR 中调用的生命周期只有 beforeCreate 和 created，这就导致在使用三方 API 时必须保证运行不报错。在三方库的引用时需要特殊处理使其支持服务端和客户端都可运行。部署构建配置资源的支持，劣势在于运行环境单一。程序需处于 node.js server 运行环境。服务器更多的缓存准备，劣势在于高流量场景需采用缓存策略。应用代码需在双端运行解析，cpu 性能消耗更大，负载均衡和多场景缓存处理比 SPA 做更多准备。

大列表用虚拟列表，原理知道一些，但没有自己写过，一般直接用第三方库，比如 react-virtualized，vue-virtual-scroll-list，react-virtualized-auto-sizer

按需加载，import 语句可以合理的加上 preload/chunkname 这种注释配置。

# 容器

# react

dev 工具 React Profiler 进行性能分析，也可以通过 Profiler 组件来分析组件的具体数据，还有一些 hook 比如 useWhyDidYourUpdate 可以帮助我们分析数据变更。

层级多的状态使用不可变数据， immer 来减少意外的更新。

像什么 memo/useMemo 也不一定到处都加，毕竟对比也是有成本的。简单的计算就不要加了，没有什么太大的意义。

我建议尽量少写 class 组件，原因有很多 class 因为需要进行 polyfill 所以打包后体积比 function 更大，class 组件不是真正意义上的面向对象，如果用箭头函数的话，实际上是为每个实例都创建了一个新的函数，而不是共用原型链。还有一个原因是 shouldComponentUpdate 这个方法说实话一般人很难掌控好。

Context 尽量只保存一些不经常变但是到处都用的数据，比如 theme，locale，user 这种数据。如果是一些经常变的数据，那么就不要放在 context 里面，因为 context 里面的数据变了会从 provider 开始向下遍历子组件并强制将它们标记更新，然后从每个需要更新的子组件开始向上冒泡属性，这个遍历的过程也是比较浪费时间的。尽量用一些基于发布订阅的库来代替，比如 mobx，redux，rxjs，xstate，zustand，这些库都有自己的优势，我自己也开发了一个基于 immer 和 useSyncExternalStore 的状态管理库，使用体验上还不错。

在子节点类型一致并且纯文本渲染的场景下不加 key 或者 key=index 效果可能会更好，虽然有点反常识。

# vue

v-if/v-show, v-if 会销毁组件，v-show 会隐藏组件，如果频繁切换的话，v-show 会更好一些。

Object.freeze()

# css

加载性能比如不要用 import ，压缩啊等等，主要是从减少文件体积、减少阻塞加载、提高并发方面入手的。

选择器性能我之前看过一点理论说是减少 css 选择器的数量，但其实现代浏览器的性能已经很强了，所以不用特意优化。

渲染性能渲染性能是 CSS 优化最重要的关注对象。页面渲染 junky 过多？看看是不是大量使用了 text-shadow？是不是开了字体抗锯齿？CSS 动画怎么实现的？合理利用 GPU 加速了吗？什么你用了 Flexible Box Model？有没有测试换个 layout 策略对 render performance 的影响？

可维护性、健壮性命名合理吗？结构层次设计是否足够健壮？对样式进行抽象复用了吗？优雅的 CSS 不仅仅会影响后期的维护成本，也会对加载性能等方面产生影响。

# 管理

1. 确定优化的目标和预期
2. 确定技术方案
3. 项目排期和执行
4. 进行项目复盘

对比原先数据优化一定比例，比如 TTI 耗时减少 30%。通过对竞品进行分析确定目标，比如比竞品耗时减少 20%。

为什么不能将前面提到的全部技术方案都做一遍呢？显然这是不合理的。主要原因有两个：

性价比。项目开发最看重的便是投入产出比，对于不同的项目来说，不同的技术优化方案需要投入人力不一样，很可能需要的投入较多但是优化效果可能不明显。
根据每个优化点的优化效果，以及相应的工作量评估，以预期为目标，选择性价比最优的技术方案。

确认技术方案，以及分工合作方式。拆分具体功能模块，分别进行工作量评估，输出具体的排期时间表。标注资源依赖情况和协作存在的风险，进行延期风险评估。

因为方案设计考虑不周，部分工作需要返工，导致项目延期
在项目进行过程中，常常会遇到依赖资源无法及时给到、依赖方因为种种原因无法按时支援等问题，导致项目无法按计划进行
团队协作方式未对齐，开发过程中出现矛盾，反复的争执和调整协作方式导致项目延期
一个项目能按照预期计划进行，技术方案设计、分工和协作方式、依赖资源是否确定等，任何一各环节出现问题都可能导致整体的计划出现延误，这是我们不想出现的结果。

因此，我们需要主动把控各个环节的情况，及时推动和解决出现的一些多方协作的问题。

有效的复盘，可以达到以下的效果：

及时发现自己的问题并改进，避免掉进同一个坑。让团队成员知道每个人都在做什么，团队管理不混乱。整理沉淀和分享项目经验，让整个团队都得到成长。把一件事做好是必须的，但将这件事分享出来，可以同样给团队带来更多的成长。

通过对项目进行复盘，除了可以让团队其他人和老板知道我们做了些什么，更重要的是，我们可以及时发现自身的一些问题并改进。
