- [重复造轮子](#重复造轮子)
- [前端架构](#前端架构)
- [API 代码生成服务(服务端生成结合 CLI 更新工具)](#api-代码生成服务服务端生成结合-cli-更新工具)
- [immer-external-store](#immer-external-store)
  - [immer 的原理？](#immer-的原理)
  - [zustand 原理？](#zustand-原理)
  - [useSyncExternalStore 原理？](#usesyncexternalstore-原理)
  - [Redux Toolkit？](#redux-toolkit)
  - [性能问题？](#性能问题)
- [命令式弹窗](#命令式弹窗)
- [埋点助手](#埋点助手)
- [提高易用性的 HOC](#提高易用性的-hoc)
- [楼盘户室号选择](#楼盘户室号选择)
- [静态网页加工](#静态网页加工)
- [爱房测试环境代理服务](#爱房测试环境代理服务)
- [巧房微前端重构](#巧房微前端重构)
  - [single-spa 转 qiankun ？](#single-spa-转-qiankun-)
  - [百度地图加载问题，严格来说是跨域 jsonp 脚本的加载问题。](#百度地图加载问题严格来说是跨域-jsonp-脚本的加载问题)
  - [html entry 的加载方式会多一次请求，导致打开页面慢几十毫秒](#html-entry-的加载方式会多一次请求导致打开页面慢几十毫秒)
  - [子应用本地开发阶段就去加载主应用？](#子应用本地开发阶段就去加载主应用)
  - [jsonp 原理？](#jsonp-原理)
  - [相对于 single-spa, qiankun 有什么优势？](#相对于-single-spa-qiankun-有什么优势)
  - [qiankun 的工作流程？](#qiankun-的工作流程)
  - [qiankun 沙箱机制？](#qiankun-沙箱机制)
  - [预加载](#预加载)
  - [路由劫持？](#路由劫持)
  - [样式隔离： shadow dom 方案、scoped 方案](#样式隔离-shadow-dom-方案scoped-方案)

面试官你好，我是面试贵公司前端开发岗位的王子顺，2019 年毕业于广东工业大学计算机科学与技术专业，简称计科，目前从事前端开发已经 3 年半，就职于 58 安居客。技术上我能够熟练的使用 React、Vue、TS 进行开发工作，还有少量的 RN 开发经验，并且我还了解 Nodejs，能够有 cli 工具和 node 服务的开发经验，其他技术点还有微前端、shell 脚本、并且对工程化有一定的认知。另外我在公司中经常进行技术分享，获得过优秀员工和年度优秀讲师的荣誉。带领过两个新人并且都顺利晋升到下一职级。简历中的前三个项目经验都是我在业务迭代过程中发现的痛点并孵化出来的技术项目。最后希望能够有机会和贵公司合作，我的介绍结束了，谢谢。

我个人认为，所有我觉得方便的地方，一定是有人在背后绞尽脑汁做了大量的优化改善，工作只会转移不会消失。就好比现在特别火的 chatgpt，GitHub 的 Copilot，我们觉得特别好玩好用，背后的开发者也是投入了海量的人力物力。还有前两年特别火的低代码、无代码，工作量并没有消失，他只是转移到了另外一帮人的身上或者是变成了另一种方式。但总的来说咱们开发者一直都在探索更高的效率，为了跑到更快更稳，咱们这帮程序员也一直乐此不疲的造轮子，所以说能够消灭程序员的只有程序员，不好意思不好意思，扯的有点远了。

# 重复造轮子

我觉得不要重复发明轮子、和不要重复造轮子还是有一定差距的。发明轮子我觉得是从三角的、四角的多边形的，到最后圆滚滚的这个叫发明了一个轮子，它能够帮助我们解决某一个问题；然后造轮子就是实心的、空心的，木头的、钢铁的、橡胶的，自行车汽车飞机。
我觉得重复造轮子并不是不可取，不管是抄来的还是在前人的基础上进行改良，都是对自己技术的磨练，也是更深层次的学习。因为只有我自己能做出来的，才是我真正学会的。

# 前端架构

往小了说可以是文件目录的规划，往大了说可以是： webpack 配置、 CI/CD 流程、前端项目的脚手架
个人理解，架构是为了解决某一个具体问题，而将各种技术合理融合在一起并解决了这个问题的方案。React、Vue、Angular 这种框架背后更有架构了。虽然都是类 MVVM 架构，但因框架本身的设计思想（或称作技术实现）不一样，导致整体架构设计就不一样。Webpack、Rollup、Vite、Esbuild 都是构建工具，又是因为它们的设计思想（或称作技术业务）不一样，导致选择的技术及技术组合使用的方案不一样，也就体现出了架构不一样。
架构是为了解决问题而生，灵活运用各种领域技术来解决你遇到的问题，而这种灵活运用的能力就是架构，甭管我用什么，只要能解决问题，就是架构，如果解决的非常优雅，那就是一个优秀的架构。

# API 代码生成服务(服务端生成结合 CLI 更新工具)

那个我可能有点跑远了，如果你感兴趣的的话我就继续，如果不感兴趣的话那咱就换个问题。

- 说一下这个项目？
  这个项目是基于 openapi-generatoer 进行的二次开发，我先说一下 openapi-generatoer，他能够将 openapi 或者 swagger 文档转成代码文件。于是我在他的基础上，实现了服务端生成代码文件，并且结合 cli 工具去更新本地仓库。其实像代码生成这样的工具市面上已经有很多了，比如 apifox 还有一些 vscode 插件都可以生成代码。其实市面上的工具我用过好几款，发现他们有一个共同的问题，就是需要人工去操作生成代码，这样其实有很多问题，一个是我们程序员都比较懒嘛，在一个是如果生成的代码文件都放到项目里，merge 合并的时候很容易产生冲突，这个问题其实很痛苦，只能重新生成，体验非常不好。所以我的目标就是这个过程自动化，让代码生成的过程不需要人工干预。

- 工作流程是什么样的？
  项目的核心思路是由 node 端去生成代码文件，开发者在项目中通过 cli 工具来接受文件的更新。
  项目的必要条件是，后端服务使用 swagger 或者是 openapi 这些社区最流行文档格式，没必要自己去重新实现一套文档解析的工具。

  我这个服务需要与集团现有的云平台进行集成，因为当后端更新代码的时候，我得知道是哪个集群的那台 pod 机器触发了部署动作，我要等他部署完成后通知我这边的 node 服务，触发代码文件的生成动作，生成后需要经过一个简单的单元测试，再将文件推送到 git 仓库和 npm 仓库，到这一步代码生成的流程就结束了。node 端除了生成，还通过 socket.io/server 维护了一个 Websocket。生成完成后会在 socket 中进行广播通知，再之后就是 cli 工具的任务了。

  cli 工具需要在本地仓库启动 dev 命令的时候一起运行, 运行的时候会先去读取 packagejson，筛选出需要更新的依赖包，然后通过 socket.io/client 加入到房间中进行依赖版本的对比任务，如果发现本地有依赖包需要升级，那么就会调用 npm/yarn/pnpm 来升级这个包。

  这个时候其实还有一个问题，对于某个后端服务来说，他的集群中有非常多的 pod 机器，而我这边会为每个 pod 机器都生成一份代码包，换句话来说，就是每台机器对应了一个需求，那么作为前端开发者来说我肯定期望能直接拿到他正在开发的需求对应的代码包，所以要想使用体验比较好的话，我得满足他这个需求。这个问题我解决方案其实不够优雅，（不知道您有没有用过 npm 的 dist-tag，他其实像是一个指针，可以指向任意版本，比如说 npm install react，其实是安装了 react 的 latest tag 指向的版本，dist-tag 可以自己定义并且可以自由指定版本，比如说有 0-9 十个版本，我可以让 latest tag 指向 version0 也可以让他指向 version9，除了 latest 这个默认的 tag，还可以自己定义其他的, npm publish --tag test），首先是 pod 机器都有一个自己的内网 ip，咱也别管他是 172.20 开头的还是 192.168，我利用这个 ip 给 git 仓库建立分支，只要是这个 ip 生成的文件我都会推送到这个分支上，同样的 npm 仓库也会有属于这个 ip 的 dist-tag，只要是这个 ip 生成的代码包在发布之后我都会更新他的 dist-tag。这样我就实现了以 pod 机器 ip 纬度进行管理的代码文件。然后我还需要一个配置文件，开发者得告诉我他需要哪台机器的代码包，我就会帮他下载对应的版本。

- 遇到了什么问题？
  这个项目是我周末脑袋瓜一热搞出来的，问题还是很多的。先说一个我遇到的最傻的一个技术问题吧，因为傻印象才深嘛，在 node 端生成代码需要运行 shell 命令嘛，但是在运行工具的过程中他偶尔会报错，这种偶现的问题就特别难默认，我排查了很久才发现问题，因为我 shell 脚本用的是 exec 去执行的，exec 限制了缓冲区，工具执行过程中会输出大量的日志，导致缓冲区爆掉了。然后我换成 child.spawn 就好了。因为经验不足产生了这个特别傻这个问题。

  首先是更新的方式，基本思路是通过 node 服务生成文件，cli 更新文件，但是具体怎么更新也是一个大问题，比如我可以将每个后端服务都单独生成一个依赖包，直接 npm install yarn add，这样代码冲突限制在了 packagejson 里，但是依赖包的方式又会引入版本管理的概念；另外一种是直接下载文件到项目目录中，这种方式为了避免代码冲突问题，只能是搞一个临时文件夹，类似于 umi 或者是 webpack 的缓存文件夹，这种方式的升级版是 git submodule。总的来说我还没有想到一个超级完美的方案，目前是只实现了 npm 包的方式进行管理，因为简单嘛。

  后期的问题也很多，都是还没有解决的问题。
  还有一个重复生成的问题，同一个后端服务可能同时部署了好几个版本，意味着需要对所有的版本都生成一遍，我目前是加了一个队列进行控制，因为是单机单实例服务所以不会有并发问题，但是如果是多实例的场景就完蛋了，如果之后需要加机器的话，还需要再设计一下。队列的设计：以后端服务的维度来划分队列，每个服务都有一条自己的队列，云平台机器部署成功后会请求生成代码文件，根据这个请求会拿到 pod 机器的 ip、仓库和版本号，我会把它当做一个事件加入队列，加入之前会去通过 git-tag 来确定这个仓库的版本号是否已经生成过，或者是不是在队列中，避免重复生成。

  生成的文件体积，开源工具的默认模版体积比自己写接口要大百分之十多一点，比如两千个接口自己写可能需要 100k，生成的代码就需要 110k，120k 的样子，差距还是挺大的，所以需要自己定制模版。
  现在后端服务的配置文件都是我写在代码里，所以还需要设计一个服务注册的机制。node 端在生成代码后会推送到 git 和 npm 上，因为是大量的文件读取所以生成性能上很差，当然现在用的还比较少。

# immer-external-store

- 为什么要做这样一个东西？
  社区的一些状态管理工具我也有过使用的经验，往大了说有 redux、mobx、zustand、constate，zustand 是我用过最舒服的状态管理库，但我个人感觉还是差点意思。react 的社区生态，往好了讲是百花齐放，说不好听的就是没有一个统一的标准，每个人的审美都是不同的嘛，你有你的定海神针，我也要我的九齿钉耙。再说了，人要有梦想，万一火了呢。

- 优势是什么？
  简单容易上手，api 设计上我尽量往 React.useState 靠齐。比如初始化 store 的时候，既支持普通对象也支持函数或者是异步函数，我们的很多业务场景都是需要先请求接口再进行渲染。（相比于 hook 的方式来说少一次更新，比如 useReqeust 不知道您有没有用过，他是先有一个 undefined，然后变为 loading，最后再次更新 state，除了第一次 mount 还需要再更新 2 次。但是异步创建 store 的话就只需要额外更新一次,当然这个差距很小。）

  第二个优势是支持两种类型的选择器，我们在写 redux 或者 zustand 的时候如果需要支持按需更新的话, 需要一些 Selector 的操作, 就是通过方法去选择你想要的数据。我的工具除了方法选择器之外，还支持字符串路径的选择方式，比如说你的状态是 a 嵌套 b 嵌套 c，那么你就可以 useState 字符串('a.b.c') 来拿到这个数据，最重要的一点是 ts 类型支持也很友好，可以提示你都能输入什么字符串，我觉得这个用起来是非常方便的。而且从某种意义上来说，使用字符串去获取对象中的某个值的方式，因为我是用 new Function 去构造一个函数并缓存，减少了 function 关键字，所以打包出来的体积一般来说比方法选择器更小，但是内存占用方面可能有一些的问题。process.memoryUsage()/performance.memory

  第三个优势是直接内置了 immer，相对于其他的状态库虽然可能不够纯洁，但非常适合在实际场景中去使用。因为 redux/zustand 这些其实在使用的过程中也会用到 immer，但是中间件的结合方式我个人觉得不是特别的优雅。

- 有遇到什么问题吗？
  做这个项目其实是一个偶然，因为我在在学习 redux 的源码的时候，看着看着发现好像我自己也能实现一个状态管理库，然后我就尝试着安装预想的思路写了一下，发现走的通而且使用上还不错，于是世界上就又诞生了一个状态管理库。

  其实现在从技术角度看来我这个库的代码是非常简单的，当时开发他也就花了一整够周末的时间，刚好两天，后来零零散散的发现一些问题就打打补丁，简单的重构一下。花费最多的是在写 TS 类型，你也知道，使用者有多方便，库开发者写类型就有多痛苦。前面也说了这个工具还支持字符串 path 的使用方式，怎么更友好的去提示这个字符串我是绞尽脑汁都没想出来，后来参考了大量的代码终于让我抄到了，当然我到现在也没看明白他咋整的，这个东西他不只是能够提示有 a.b.c 字符串可以选择，他也得支持从 a.b.c 推导出值的类型，也就是说能从对象推导出都有哪些路径还得从这个路径推导出值的类型，这个东西我真的是没看懂。

  还有就是 use-sync-external-store， 这个 api，react18 才有的，后来在 zustand 的源码里看到有 react16、17 用的 polyfill 版本。所以我也不需要担心版本低用不了的问题。

  然后就是打包细节上的优化， 因为我是用 rollup 加 babel 插件打包的，所以看的比较清晰，比如说一个简单的 typeof 关键字，如果只是 typeof === function 或者是 typeof === string 的话没有问题，但如果是 typeof === object，那么 babel 会引入一个 typeof 的 polyfill 函数来兼容 symbol 类型，gzip 后不到 100b，我一个小小的库肯定是希望极致的精简，就要配置一下 babel 去掉这些代码 exclude@babel/plugin-transform-typeof-symbol。
  还有另外一种细节，比如，函数的默认参数、可选链式符，async/await、参数扩展运算符，其实换个写法也能实现的这种我都会换一个写法。

  说实话，这些细节加起来，对于我这个 100 行不到的库来说，打包出来的代码可能会有 500b 左右的差距， gzip 后应该有 200b。我没有实际去测量过，但应该差不多。有的时候我也会觉得我为了这么点东西浪费了时间效果还不大，但我觉得这些都是经验，实践过一次之后下一次就知道怎么样做才是最佳方案，只有在最开始探索的时候会花多一点时间，而且这点经验在做性能优化的时候其实还是有那么一点点参考价值的。

  现在我团队里的有五个项目都在用这个库。

## immer 的原理？

copy on write, 写时拷贝。就是在 写 操作的时候，进行浅拷贝，然后写入属性，这个时候，copy 和原来的 state 共享了除 写 属性之外的所有属性.

通过 Map 来记录复制后的对象，Map 中的 key 就是原始对象中的值，Map 中的值就是修改后的草稿。第一步是通过 proxy 对原始对象进行代理，核心是代理 get 和 set，get 主要是懒代理，就是针对每一个访问到的 target.key 再次代理，因为在 js 中的赋值语句是分为两步的，他要先读再写。set 劫持就是将 target 浅拷贝一份，然后在 copy 的对象上进行赋值，之后再存到 map 中，set 中的 target 就是访问到的具体的值。写完草稿之后会递归访问原始对象中的每个属性，看看他们在 Map 中是不是被标记过，如果被标记的话就取出来放到新对象上。就是很经典的写时拷贝

immutable 对象所要保证的就是每次更新需要产生一个新对象。同时考虑性能问题，就需要保证对象只是发生改变的属性产生新的引用，其他没发生改变的属性仍然使用旧的引用。
不可变数据 就是一旦创建，就不能再被更改的数据。对该对象的任何修改或添加删除操作都会返回一个新的对象。要避免深拷贝把所有数据都复制一遍带来的性能损耗，使用 Structural Sharing（结构共享），即如果对象树中一个节点发生变化，只修改这个节点和受它影响的父节点，其它节点则进行共享。

produce 的工作分为三个阶段，分别为创建代理（createDraft）、修改代理（produceDraft）、定稿（finalize），创建代理所做的就是对传入的第一个参数 base 对象进行代理，实现后面修改代理时，也就是传入的回调函数执行时，可以进行 ShallowCopy on write 的操作，最终定稿就是把进行修改的对象的引用指向 ShallowCopy 的对象上面。

immer 实现深拷贝的过程分为 draft 和 commit 两个阶段的，其实这个和 git 很像。然后在学习 react 的过程中，但是也感觉有些相似，react 渲染的过程也是 draft 和 commit ，virtual-dom 似乎就像是一个 draft 的过程，最终 commit 才是真正同步的过程

读的时候判断是否被修改过，没有就直接返回，

## zustand 原理？

最开始的 zustand 是通过观察者模式 + useState、useRef、useEffect ，在 effect 的时候来进行对比实现的数据更新同步，然后又加了一个中间件的机制。后来有一个版本更新，使用了 观察者 + useSyncExternalStore 实现。

版本一：创建 store 拿到对外暴露唯一接口 useStore ，定义全局状态。通过 const bears = useStore(state => state.bears) 获取状态并与组件绑定。这一步 store 会执行 subscribe(listener) 添加订阅操作，同时该方法内置有 forceUpdate() 函数用于触发组件更新。使用 set 钩子函数修改状态。即调用的 setState 方法，该方法会执行 listeners.forEach((listener) => listener(state, previousState)) 通知所有订阅者执行更新。

版本二：的要点在于 useSyncExternalStore 的实现，

## useSyncExternalStore 原理？

这个 api 接收三个参数，subscribe、getSnapshot、getServerSnapshot，其中 subscribe 是订阅函数，getSnapshot 是获取快照函数，getServerSnapshot 是获取服务端快照函数，另外他还有一个高级版本 useSyncExternalStoreWithSelector，额外接收 selector 和 equal 两个参数，就是从 getSnapshot 中获取的数据进行了一次选择，equal 就是自定义的对比。

和其他的 hook 一样也分为 mount 和 update，mount 的时候会 mountWorkInProgressHook ,执行 getSnapshot 并把结果赋值给 hook.memoizedState，hook.queue 上保存 state 和 getSnapshot， 然后通过 Effect 去执行 subscribe，并传入内部的更新钩子，这个时候我们外部的观察者就收集到了内部的更新钩子。当数据更新的时候我们需要自己去执行观察到的钩子函数来触发 react 的调度更新 forceStoreRerender。update 的时候会通过 updateWorkInProgressHook 拿到 hook，并且执行 getSnapshot，然后将 memoizedState 也就是上一次的快照进行对比，如果有变动那么久标记这个 fiber 接收到了更新。为了保证数据的一致性，react 在 commit 阶段还会再额外检查一下数据有没有被修改过，如果有的话还会再发起一次调度更新。这是因为 concurrent 模式的 render 过程中外部数据可能已经发生了改变，但是更新的优先级没有变，导致 scheduler 不会取消正在执行的任务，导致 render 过程中使用的数据与 store 中的真实数据有差异，为了保证数据的一致性，就只能在 render 之后的 commit 阶段再次检查。同步模式中如果是比较早的 effect 也可能会导致这个问题。这就是官网上反复提到的撕裂 tearing。

兼容处理是靠订阅和 forceUpdate 解决的。关键点在于那个 useLayoutEffect 部分，其中判断了外部状态的最新值与渲染的值（capture value）是否一致，不一致就强制更新（并且是同步的），最终效果仍是用户会最终得到一个一致的渲染结果（但中间还是会有 tearing，只是因为同步更新的原因，浏览器直到控制权交回后才会绘制 dom）

## Redux Toolkit？

我不喜欢 redux 的一个原因是模版代码太多，还要定义各种 reducer type， 感觉搞的特复杂。toolkit 是针对 react 做了一些易用性的封装，提供了很多的 api，configureStore/createSlice/useSelector/useDispatch，还需要结合 context.Provider 才能玩转一整套，这一套东西光是听一听就脑瓜子大，可能是我的小脑袋瓜容量不够大，记不住这么多 api。当然不可否认的是它里面有很多代码是非常优秀的， 比如说 compose 函数，比 koa 还要简洁的洋葱模型，震惊我好久。

## 性能问题？

根据我的分析，不会产生性能问题。首先假设在 100 个地方用了 useSyncExternalStore，然后去执行所有订阅函数，对于第一个执行的订阅来说，react 会以同步优先级调用 scheduledCallback 创建一个 task 进行调度，但是对于剩下的 99 个订阅来说并不会为他们创建 task 进行调度，因为他们产生的渲染优先级 line 是一样的，在 scheduledCallback 之前会判断当前的渲染优先级，和下一次更新优先级，相同的时候就直接 return 掉了，相当于节流处理。

其实我写完这个库的时候，感觉 react 越来越像是一个操作系统，如果作为一个 view 层来说，他的侵入性越来越强，离 view lib 越走越远了，感觉挺魔幻的，可能这就是大佬们的目标吧。

# 命令式弹窗

- 都做了什么事情？
  其实这个不是我发明的，我是针对业务做了一些改进。比如说一些弹出层的对话框，model\popuper\alert\message, 在 jq 时代都是$.medel()直接调用，这个叫命令式调用。但是现在我们写 react、vue、rn 的时候，一般都是写个标签，然后通过 visible 属性来控制显示隐藏，这个叫做声明式调用。当然也有一些 ui 库比如 antd/ele-ui 也提供了命令调用的方式。

  我参考 antd/eleui 的实现，自己设计了一套命令式调用的工具规则，针对 react/vue/RN 分别实现了三套控制显示隐藏工具，业务上就负责写弹层以及内容，这套工具会帮助开发者把弹层组件转变成命令调用的方式。

- 为什么要做这样一个东西？
  21 年重构巧房房源系统的时候，我负责了一个页面，说出来你可能不信，这个页面上有 18 个弹窗，十八个呀，我印象特别深刻，用了足足 18 个变量来控制显示隐藏，最要命的是还有弹窗嵌套的场景。我当时接手的时候脑瓜子嗡嗡的。然后我就在思考为什么会这个样子，不是说其他人技术水平差，而是在思考为什么写 JSX 会出现这种情况，我要怎么去避免这种情况。我就想着翻一翻 antd 的代码看看能不能以一种优雅的方式去解决这个问题。然后我就翻到了 alert/message 的 api 调用方式，我发现我可以参考他的思路来实现这样一个公用的工具函数，没有直接用他实现的方法主要有两个个方面的考量，一个是按绝对路径从包中直接导出方法，不够稳定，万一他以后升级了把方法挪了位置或者是做了破坏性更新，那么对我来说是灾难性的问题，第二个是我想实现 react/vue/RN 三套，有一点自己的想法，造轮子的心蠢蠢欲动。

- 是怎么做的呢？
  主要就是主要是新建一个节点，把节点添加到根上，再把组件挂载上去，整体的思路类似 HOC 的写法，写一些 visible、confirm、cancel，业务弹窗组件可以在 props 中取到这些东西。另外为了更好的交互，还包了一个 promise，在 confirm、cancel 时会 resolve/reject 结果，这样使用的时候就不需要额外写回调函数了。

- 有什么难点吗？
  难点不在 visible\confirm\cancel 这些 api 上，而是在组件的挂载和管理上两个方面，这个有点反直觉。
  react 和 vue 问题不是特别的大，只需要 create div 并 append 到 body 上，然后通过 render 或 mount 把组件挂载到 div 上就好，只不过需要做一些版本兼容，因为 api 有 break change，另外还需要再维护一个的实例池 instance pool，方便去销毁创建的所有根实例。RN 有点不一样，创建一个新的根实例是通过 AppRegistry 注册一个根组件 registerComponent/unmountApplicationComponentAtRootTag，但是已经有第三方库实现了比我想的更完善的一套挂载卸载的管理机制，所以直接用就好，react-native-root-siblings。

  react 因为 18 后做了破坏更新，新增了 createRoot 来代替 render， unmount 的方式也有点不一样，之前可以直接使用 unmountComponentAtNode 卸载 app, 之后要用 root.unmount 来卸载。所以兼容一下这些 api 就好。

  Vue 也差不多，之前是直接 new Vue Component 就好，vue3 之后需要通过 createApp 来新建一个 app 实例，$mount 和 $destroy 也兼容一下就好，mount/unmount

- 有什么好处？
  相对于声明式的 visible 控制，命令式调用能够减少一些样板代码，对于弹窗嵌套的场景也能更好的进行控制，另外进行代码分割也更加自然。

# 埋点助手

这是一个代码埋点的工具，开发这个工具的有两个目的，第一个是磨平埋点平台之间的差异，让开发者只需要关注业务埋点的逻辑，而不需要关注埋点平台的差异。第二个目的是提供更优雅的方式去埋点，还要有完善的 TS 类型支持，目前提供了两种方式的埋点，一种是传统的函数调用，另一种是通过装饰器的方式。提供了页面停留时长的监控

项目是我入职后写的第一个脚本工具，当时不管是 react 还是 vue 都在用 class 组件，所以开发的重点放在了装饰器的开发上，需要针对 class/property/method 做不同的处理，

比较困难的是属性装饰器，因为 react 会写箭头函数，babel 针对属性是箭头函数的做了一层处理，导致 descriptor 会多一个 initializer 的属性，这个属性会在类初始化的时候被调用然后返回 bind 后的方法，需要针对这一点做个兼容。装饰 method 需要修改 value，装饰属性需要通过 defineProperty 修改 get/set，主要是进行切面处理，同时还要支持多种类型的参数，比如字符串、对象，数组、函数。

# 提高易用性的 HOC

- withReactLazy 怎么封装的？
  一般写 React.lazy 写的时候需要有四个点，import 语句、 suspense，fallback 。这四个点里面，只有 import 语句必须得是开发者自己写，像 suspense 和 fallback 因为写法非常的单一，所以可以进行结合，这样一个简单的 HOC 就完成了，当然还可能需要处理一下 ref ，另外为了能更好的支持类型推导，还需要做一些 TS 范型的处理。这只是一个最基本的 HOC 封装，还可以再接着这个基础的 lazy HOC 思路进行扩展延伸。比如 lazy 后的组件不论他展示与否都是要进行异步加载的，但我们可以结合 IntersectionObserver/或 scroll 事件，在代码分割的基础上实现组件的懒加载，，也可以再结合 ErrorBoundary 来处理模块报错。

  相对于开发者自己去写 lazy/suspense/fallback，这样的封装能够减少一些样板代码，有的开发者可能就是因为需要写这些样板代码才不愿意去使用 lazy，这样的封装能够让开发者更愿意去使用 lazy。当然，代价就是 HOC 封装比较抽象，有一些理解成本。

- withSkeleton 怎么封装的？
  接收两个参数，第一个是组件，第二个是判断方法，思路大致类似于 React.lazy 的，就是对原来的组件 props 进行一个劫持，通过判断方法来决定是否展示骨架屏。但是这里有一个限制条件，就是组件数据必须通过 props 传递才可以。

- 问题？
  其实问题不是特别多，可能会导致开发者插件的展示上不够友好，但我们做的时候尽量把 displayname 这种静态变量用起来。
  对于原始组件的一些静态方法属性也需要继承过来 hoist-non-react-statics
  当然也不一定非得用 HOC 的方式，hooks\cloneElement 都是不错的选择。其实网上说的 hoc 的优势 渲染劫持 属性代理啊，喜欢讲一些名词搞的很神秘一样，我还没有遇到过那种 HOC 可以但 HOOKS 或其他方式无法实现的场景，针对某一场景用某个方式写起来比其他方式更爽的情况时候，我就会选择这种方式，仅此而已。

# 楼盘户室号选择

- 您是觉得这些组件的写起来没什么挑战是吗？
  我还写过一些业务专用的组件，最近的一个是去年写的 autocomplete 联动搜索组件，组建需求的目的主要是为了提升经纪人选择楼盘、栋、单元、房号时的便捷性以及降低前端开发的使用成本。在我们做房产业务的人眼里，这是一个比较核心的功能点。最基本的交互上是一行选择框，最少一个，最多四个，分别对应楼盘，和可选的栋、单元、房号进行排列组合，简单标记成 1234 号选择框，第一个功能点是，只有当前面的选择框完成后才可以进行后面的选择，并且后面的选择框的类型是由前面的选项来决定的排列组合。第二个功能点是，前面的选择框变更后，后面的也要一并清除，并且自动搜索并打开下一个选择框。这里有个潜在的条件是，每个选择框都得知道他前面都有什么选择框，并且拿到他们的值再去调接口获取选项；第三个功能点是能够当作 antd 的 FormItem 来直接使用，也就是支持定制化的表单项。这是三个核心的功能点，还有一些细枝末节的就不再说了，这个组件乍一听的时候，有点像级联选择器，类似面板的那种，但可惜不是，因为他不光可以选择，还允许手动输入，归根结底是巧房 SaaS 系统需求采集自经纪人，他想要啥样的我们就要做成啥样的。

- 其实拿到这个需求的时候我也很头大，因为我目前的工作重心主要在爱房，因为巧房团队的组件开发大部分都是自己认领的，我万万没想到会被老板抓到巧房做这个组件。
- 设计思路
  我一开始的设计思路很朴素，就是是一个容器包含四个选择框，然后进行状态控制，但是我很快就发现这样设计的话复杂度会异常的高。因为对于每一个选择框来说，它的显示隐藏是由前一个来决定的，查询条件需要前面选择框的值，并且还得能够控制后面选择框。如果我硬要采用朴素的方式来写其实也能实现，但这样实现的话几乎是没有任何扩展性的，状态控制也比较多，节点的类型、显示隐藏、访问前后节点的能力，考虑到后面的迭代维护对任何人来说都是比较痛苦的。就算设计方案通过大家的考验了，代码 review 阶段肯定也很困难。然后我就想了第二个方案，主要的改动点是加入了双向链表结构，每一个选择框对应一个节点，链表的长度可以动态决定，每个节点都可以访问它的前驱和后驱。这样我只需要开发两个组件就好，一个是容器组件，一个是 item 组件，容器组件负责维护链表以及控制每个 item 的 select/search/focus/blur 动作，然后通过遍历链表去渲染 item，item 其实就是一个比较原始的 antd select 组件，主要是使用链表节点上存放的一些属性，并且传递 ref，以及做一些默认值的处理。其实到这里就会明显的感觉到整个组件的开发难度下降了很多。而且这个组件的扩展性也非常好，应用场景不会局限在楼盘户室号选择这一个地方，总的来说还是一次比较成功的组件开发，利用数据结构降低开发复杂度。
  因为是去年开发的，再具体的细节就记不太清了。

# 静态网页加工

- sketch 转 html 这个是北京那边人搞出来的，他的技术实现我没有看过，不清楚。
- 这个东西是一个 sketch 插件，主要是提供给 UED 设计使用的。这个插件可以导出 html。但是问题在于，ued 导出 html 后需要上线又不具备这样的技能，所以就需要找开发来上线，最开始前端也只是单纯的上传到 cdn 就好。但后来产品又需要统计一下数据，要求能够进行埋点。这个时候我就意识到产品未来可能要的越来越多，于是就想着做这样一个 html 预处理工具，能够对纯静态的 html 进行自定义的预处理操作。其实就是利用正则工具针对字符串进行匹配转换，只是转换的种类比较多，比如埋点，就是在页面中添加一个相对路径的 script，然后在对应的 js 文件中添加写好的埋点代码，使用者只需要在 js 中改改参数就好。再比如图片懒加载，其实就是匹配 img src 标签，然后替换成 data-src ，再在 head 中添加图片懒加载的脚本。还有 video 的处理，就是利用第三方的播放插件进行 video 标签设置 mediaelementplayer，让他在 webview 中也能进行比较好的交互。
- 这个工具是我 20 年写的，那个时候刚入职不到一年，写的也比较粗糙。后来我们组里来应届生的时候，一般都会让他先用这个工具来上线一个网页，操作不难，比较容易获得成就感，是一个比较好的试金石。

# 爱房测试环境代理服务

- 工作流程？
  爱房测试环境是一个独立的内网域名，直接指向 nginx，在通过 loaction/upstream 进行路由转发到具体的服务集群中。
  经过我的改造，现在是内网域名指向 nginx，直接 loaction 到我的代理服务中，也就是 node 服务，在这里进行请求的转发和管理。当然 nginx 层理论上可以去掉，但是集团规定不允许这么做，所以就只好留着他。
  node 服务这里得知道一个请求要往哪里转发，首先得有一个 mapping 关系，这个关系在 nginx 上的体现就是 location/upstream，upstream 对应的是一组 ip 地址。那么 node 服务也得有这样的一层关系，但是 nginx 的配置文件被我改掉了，所以我只能去读线上环境的 ng 配置然后自己解析一下，拿到 loaction + 集群名称的 mapping。
  58 集团云平台的一个集群有四个环境，其中线下的有测试环境的稳定环境，这两个之间的区别是稳定环境的 ip 是固定不变的。那么当 node 服务接收到一个请求的时候，默认根据 mapping 关系将这个请求转发到稳定环境的机器 ip 上就好(这里我需要通过云平台的 api 来查询机器都有哪些)。这是最基本的工作流程。

  关键点在：node 服务会记录请求者的 ip 和 UA(UserAgent)，并把它当作设备指纹，同时对外提供一个 api 接口，接口参数是集群名与机器 ip。当这个接口被请求的时候，会解析拿到集群与 ip 并记录到指纹对应的配置中，那么接下来当这台机器发起的一些业务接口，在到达 node 服务时，会先根据指纹拿到配置好的 ip 后，再进行转发。这样我们就实现了一个公用的反向代理服务，因为是单机服务甚至不需要 redis，测试环境根本么那么多人用，前端部门 30 个，后端 20 个，测试 20 个，也不需要去考虑证书，因为是集团 nginx 统一配置的测试证书。

  为了进一步提供便利性，访问根路径时会返回控制台面板，可以看到当前都有哪些配置。在面板这里还可以进行 url 或者是扫码分享，可以复制一下 url 发给测试，当测试访问 url 的时候 node 服务就会生成一个新的设备指纹和配置项。这样开发和测试就可以很便捷的再各个环境之间切换。我可以给你演示一下。

- 问题？
  第一版的问题其实不是特别多，因为是我闲着没事的时候开发的，而且我当时不知道到底能不能把这个工具用起来。但是后来测试团队的老板觉得价值很高，然后就催着我老板期望能够做的更精致一点，好推广到其他部门，所以就开始了第二版的开发。
  我现在正在短短续续的进行重构工作。然后我列了几个问题点，都是还没有解决的。你想听听吗？

  1. 第一个点，控制面板的启动方式，现在是通过根路径打开，但是业务场景五花八门，根路径恐怕已经被占用了，新开一个特殊的路径也不能保证是通用的，有记忆成本，开发者得记住控制面板要怎么打开才行，我想的是在 node 服务中劫持 html 请求，并在他里面加点料，其实就是运营商劫持。
  2. 第二个点是目前 node 服务仅支持单机应用，如果推广到其他部门，可能单机性能不够。同时我又觉得这些不同产品线的应用不应该共用代理服务，所以我应该为每条产品线单独部署一个稳定的 ip，这样既不需要引入 redis, 也不需要考虑性能问题，只要让他们的 nginx 指向固定的 ip 就好。
  3. 第三个点是服务之间互相调用的问题，目前仅支持第一层请求调用，如果服务之间互相调用的话做不到链路的统一，这个问题比较棘手，微服务或者是 bff 服务可能会遇到这个问题，我还没想好怎么解决。
  4. 前端方面的交互要调整，还要再加一个历史记录，方便查看历史配置。
  5. nginx 配置里面不一定都是简单的路由转发配置，还有可能有一些特别的逻辑，这种情况下没有办法做到完全代理，但这种情况目前还没有遇到，所以优先级不高。

  我重构后的版本有个小 demo，也可以给你演示一下。比较可惜的是，我好不容易找了一个热心的后端小伙伴帮忙对接云平台，但后来他离职了，时运不济命途多舛。

# 巧房微前端重构

- 为什么要升级？
  集团在 2021 年的时候收购了巧房，希望能够把巧房的线下优势和 58 安居客的线上优势结合起来。这些集团的战略计划，在技术层面上的影响，我用大白话来说，就是把 58 安居客现有的新房二手房租房的一些页面内置到巧房当中，对于巧房的一些管理页面也需要合并到 58 安居客的系统中。我们的团队又特别多，来自北京的、上海的、西安的，加上巧房，58 安居客这边其实已经有了基于 qiankun 的微前端，也是我这边参与开发的，但是巧房的微前端是基于 single-spa，最开始的第一次融合项目是我负责用 iframe 来做的，但是效果不够理想，遇到一些的问题，导致体验比较差， 后来计划升级到 qiankun。

  iframe 跨域导致 cookie 访问异常，在高版本的浏览器中跨域的 iframe 不能直接访问 cookie，需要设置一个 samesite：node，但这个属性又有很奇葩的兼容问题。
  有些页面是放到抽屉里的，需要和外部页面进行交互，还得定制一套 postMessage 的交互协议。
  URL 不同步。浏览器刷新 iframe url 状态丢失、后退前进按钮无法使用。
  慢。每次子应用进入都是一次浏览器上下文重建、资源重新加载的过程。
  全局上下文完全隔离，内存变量不共享。iframe 内外系统的通信、数据同步等需求，主应用的 cookie 要透传到根域名都不同的子应用中实现免登效果。
  UI 不同步，DOM 结构不共享。想象一下屏幕右下角 1/4 的 iframe 里来一个带遮罩层的弹框，同时我们要求这个弹框要浏览器居中显示，还要浏览器 resize 时自动居中。

  另外还需要满足线上环境的按公司的灰度控制，这个是针对巧房的一个升级改造点。

## single-spa 转 qiankun ？

巧房存量项目有 50 多个前端项目，我需要将这些项目都改造成 qiankun，并且将 bff 服务迁移到 58 集团的云平台上，同时还要满足按公司区分流量的的线上灰度控制，这个工作量乍一看是非常庞大的。等我仔细分析的时候会发现，前端项目的打包脚本几乎一直，我只需要去改造好一个项目，然后写一些 shell 和 js 脚本跑命令去升级这些仓库，本来觉得前端仓库的升级要一周才能完成其实就用了两天。

另外 30 多个 bff 服务也是差不多的道理。只是 bff 还会涉及到云平台的集群操作，于是我就通过我的个人账户抓了一些 curl 请求然后加工一下，主要是新建集群和更新集群配置的一些请求操作，然后就可以通过脚本去批量操作了。

我修改的主要是子应用的打包方式， output.libraryTarget 从 system 改成 window。然后修改使用到 systemjs 的地方，比如 react/react-dom 这些 systemimport 进来的 lib 包，替换成 externals，然后在 index.html 里面加入 cdn 脚本。主应用就重新做一个新的就好了。

遇到的问题也有一些，有一个印象比较深的，和百度地图加载有关。还有一个 html entry 的加载方式会多一次请求，导致打开页面慢几十毫秒。还有一个是具体需求扩展出来的架构设计问题，具体需求要让子应用本地开发时，也能在主应用中运行。

## 百度地图加载问题，严格来说是跨域 jsonp 脚本的加载问题。

我们跨域开始说，百度地图一般通过 script 标签进行 jsonp 加载，这个时候是不存在跨域问题，但是 qiankun 在加载子应用的时候，需要通过 fetch 去获取子应用的资源，然后再执行，本来没有跨域问题的 script 标签，现在变成了跨域的 fetch 请求，这个时候就会报错。解决方案有三个思路，一个是我们通过服务端去代理这个 script 地址从而避免跨域，这也是最简单有效的；第二个方案是在主应用中主动去加载 script 标签，因为主应用的代码不会经过 fetch，但缺点是有的页面不会用到地图但也额外加载了资源；其实问题到这里就解决了，这两个方案都能很快的解决而且带来的副作用其实也不是很大。还有第三个方案：qiankun 提供了一个 api 叫 excludeAssetFilter，来过滤在主应用中引入的子应用资源，这可以帮助优化主应用的性能和加载速度，让这些资源避免使用 fetch 去获取从而运行在沙箱之外，可以用这个 api 把跨域 jsonp 的 url 进行过滤，等子应用使用到地图的时候再进行加载。但是这个方案有个比较特别的问题，jsonp 脚本一般会在 window 上挂一个回调函数，但是最后这个方案中 script 脚本是在子应用中加载的，所以回调函数是在沙箱中的，也就是 fakewindow 上。但是 script 实际上被放到了主应用的 head 标签中，也就是说 script 返回后的 js 脚本执行时无法访问到 fakewindow 里面的回调函数，当然这个问题也可以解决，可以把沙箱关掉，绕一点的方案也有。

## html entry 的加载方式会多一次请求，导致打开页面慢几十毫秒

这个问题说简单也简单。当时也想了三个方案，我这人就喜欢想上中下三种方案。第一种是 qiankun 也支持 js entry，但是这个方案技术上问题不大，但是我们有很多其他团队的项目，不太好插手。我渴望的是能够从一个切面上去解决这个问题，我们不是多一次请求吗，提升请求速度最佳的方案就是进行缓存，所以第二种方案是在服务端针对子应用的 html 进行预请求并加上 swr 缓存策略，再子应用 html 的内容插入到 body 里，然后在前端通过自定义 fetch 检测到子应用的 html 请求后，再去直接从 body 中拿 html 字符串，但是这个方案一听就特别绕，而且 html 字符串不能直接放到 body 中，里面的标签会被转义，如果非要放的话就要放到 textarea 中，但是增加了安全风险；所以还有第三种方案用 service worker 进行 swr 缓存，第一次肯定是慢的，但是第二次肯定会快很多，这个方案也比较完美，再搭配上 qiankun 的 prefetch 策略后，火上浇油，不好意思用错成语了，是如虎添翼；为了几十毫秒绞尽脑汁。

## 子应用本地开发阶段就去加载主应用？

这个其实是架构设计上的问题，我们开发的时候就要把子应用放到主应用中运行。首先肯定是不希望自己在本地跑一个主应用，因为跑两个项目太白痴了。实现并不困难，简单一点的可以直接配置 webpack.devServer 的 proxy 把特定的路径做个转发就好；复杂一点的就在本地启再开一个服务，页面的请求都走这个服务，对于特定的 url 请求，就直接代理到测试环境中，其他的请求依旧转发到 devServer 的端口；又因为我们后面新的项目统一用 umijs 做的，又提供了插件机制，针对这样的项目，我们可以通过插件来实现。插件实现有个好处，就是可以实现 webpack 配置的差异化，一个项目有两份 webpack 配置，一份是插件提供的统一的配置，一份是这个项目自己需要进行的差异化处理，这样我们在升级应用的时候可以直接升级插件，同时也很好的保留了差异化的配置。我个人认为这种升级的同时又能保留差异化配置真的是一个比较好的方案，因为在微前端体系下有几十个子应用，如果不把配置拆开，统一升级的过程真的很让人烦躁，纯纯体力劳动。

## jsonp 原理？

利用 script 标签的 src 属性可以跨域请求，请求成功后，然后通过回调函数的方式把控制权交还给前端。创建一个 script 标签，并将请求的 URL 拼接上一个回调函数名作为参数，服务器接收到该请求后，将需要返回的数据包裹在回调函数中，形成一个类似于 callback({data}) 的字符串，浏览器在接受到这个脚本之后会自动执行 callback 函数，这样控制权就交还给了前端，可以拿到数据了。JSONP 的优点是实现简单，且兼容性好，可以在低版本浏览器中运行。只支持 GET 请求。另外，由于 JSONP 中传递的数据是通过 URL 参数传递的，因此存在安全性问题。如果服务器返回的数据被恶意篡改，可能会导致前端数据泄露或被攻击

## 相对于 single-spa, qiankun 有什么优势？

我认为 qiankun 的优势在于 html entry 减少接入成本，但是会拖慢页面打开速度，当然 qiankun 也支持 js config 的。另外 qiankun 还提供了沙箱机制，可以保证子应用之间的 js 运行隔离、css 隔离，帮我们去处理全局变量污染和内存泄漏，但是沙箱机制也有一些缺点，比如性能问题。总的来说，我认为 qiankun 更适合子项目不可控的场景，比如 58 安居客我合作过的前端团队就有七八个，北京的西安的上海的，不可能要求人人都来认同我的规范，而 single-spa 是一个纯粹的路由控制器，所有的污染泄漏问题都需要开发者自己约束，更适合水平较高的团队使用。

其实我们现在写业务代码不用过度的去考虑全局污染问题，很少会直接在 window 上挂东西，就算挂也是 externals 出来的 lib 包或者是 eventemitter 这种工具，再加上现在的应用都经过 webpack 构建出来的，基本上都是立即执行函数 IIFE 的形式，所以我个人认为沙箱的用途其实不是特别大。css 方面也是一样，项目中一般都是 css module 或者 css in js 再或者是 tailwindcss，所以我觉得沙箱的用处也不是特别大。

## qiankun 的工作流程？

大致的流程是路由劫持，注册微应用，start 启动，空闲时进行预加载。

会先通过 single-spa 进行路由劫持，再通过调用 registerMicroApps 注册子应用, 指定子应用的 name, entry,container，activeRule, 然后调用 start 方法来启动 qiankun 框架。

根据当前的 url 和注册的路径划分为四种类型，后面依次去处理 toUnload/toUnmount/toMount/toLoad, 这里是 singlespa 做的事情。

如果当前 url 匹配到了微应用的路径那么就会去加载微应用，通过 fetch 来加载入口 html。得到 html 文本后会分析出 script 和 style, 脚本和样式有两种 inliine 和 src/link。加载远程 styles 之后，把 inline styles 和远程下载下来的 styles 文本覆盖到 html 的 style 和 link 标签。然后返回 html、assetPublicPath、getExternalScripts、getExternalStyleSheets、execScripts（script 执行器）。然后用一个 div#**qiankun*microapp_wrapper_for*微应用名字** 来包裹入口 html 内容, 接下来就是创建沙箱，通过 with 语句和创建的 proxy fakeWindow 去运行脚本执行器，拿到子应用导出的一些方法。

接下来就是挂载微应用，挂载的过程里有 loading 控制、对样式做隔离、激活沙箱、调用微应用提供的 mount 方法。

## qiankun 沙箱机制？

乾坤沙箱主要是基于 proxy 代理沙箱、切换时进行对比的快照沙箱

大致的流程是，代理沙箱主要是通过为每个子应用都创建一个 fakeWindow，然后为这个 fakeWindow 设置代理，在 with 语句中访问代理后的 fakeWindow。这个 fakeWindow 上会克隆 window 对象上可以修改的属性。
set 拦截其中会检测 fakeWindow 和 globalContext 是否都有当前要修改的属性，如果有，那么直接给 fakeWindow 上的该属性赋值，如果没有，只有 globalContext 上有，看一下这个属性是否是 writable 或者有 set 方法，只有这两个有其一，才表明这个属性本身是可以修改的，我们给 fakeWindow 上添加这个属性并修改才是有意义的，同时 set 方法中也会查看当前修改的属性是否是 globalVariableWhiteList 中的一个，如果是，将其 descriptor 添加到 globalWhitelistPrevDescriptor 中。
这个 get 其实就是做了很多的检测，比如如果要获取的属性是 window 或者 self，这种返回 proxy 本身，另外的话就是优先从 fakewindow 上获取，没有的话再去上一层的 window 对象上获取
还有一些其他的代理，has，getOwnPropertyDescriptor，ownKeys，defineProperty，deleteProperty,getPrototypeOf

proxy 的缺点也很明显，主要是性能问题，with 语句加上 proxy 代理，比原生直接访问会慢很多。

快照沙箱就是激活应用前记录 window 对象的属性，卸载后进行对比，如果有修改的属性，就还原到激活前的状态。缺点是只支持单应用激活。

另外 qiankun 还针对 setInterval、addEventListener（history）这些 api 做了改写处理，防止内存泄漏。

## 预加载

核心实现就是用 requestIdelCallback 在 cpu 空闲时预加载微应用的入口文件、以及远程 scripts 和 styles

## 路由劫持？

对 history.pushState/replaceState 方法进行改写，对 addEventListener 进行改写，当收到 hashchange/popstate 事件的时候特殊处理。

## 样式隔离： shadow dom 方案、scoped 方案

shadow dom 方案是将子应用放到 shadow dom 中，这样就可以避免样式污染，但是这个方案有兼容性问题，比如 ie11 不支持 shadow dom，所以 qiankun 也提供了 scoped 方案，这个方案是通过给子应用的样式加上前缀，监听 style 节点的变动，针对每个样式规则前都加 div#微应用名 来实现 scoped 的效果。

但这两个方案都有非常大的问题，像弹层类型的组件特别是默认挂载到 body 节点上的组件，比如 popover/dropdown/抽屉，会导致样式丢失，当然我们可以指定这些组件的挂载位置。
这两个方案都不够优雅。业务上来说，css in js 有性能问题，tailwindcss 有样式冗余问题，css module 的自由度低，总的来说整体上用 tailwindcss，局部定制用 css module 比较完美。当然，如果用的是 antd 这种组件库，可以直接也推荐 css module。
